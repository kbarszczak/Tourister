{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ca36fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing import sequence\n",
    "from keras.preprocessing import text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6abf7b4",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3c56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/tc_model_1_1680701562.h5'\n",
    "dictionary_path = '../data/small_dictionary_1680697004.pickle'\n",
    "tokenizer_path = '../models/tokenizer_model_1_1680697854.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb76ca",
   "metadata": {},
   "source": [
    "The method that loads model & tokenizer & dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21087169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(model_path, tokenizer_path, dictionary_path):\n",
    "    with open(tokenizer_path, 'rb') as file:\n",
    "        tokenizer = pickle.load(file)\n",
    "        \n",
    "    with open(dictionary_path, 'rb') as file:\n",
    "        dictionary = pickle.load(file)\n",
    "        dictionary = {value: key for key, value in dictionary.items()}\n",
    "        \n",
    "    model = keras.models.load_model(model_path)\n",
    "    \n",
    "    return model, tokenizer, dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e4dd4",
   "metadata": {},
   "source": [
    "The method takes model, tokenizer & the input text to calculate the interest vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cfb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vector(model, tokenizer, text):\n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    maxlen = model.layers[0].input_length\n",
    "    x = pad_sequences(sequences, maxlen=maxlen)\n",
    "    return model.predict(x, verbose=0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49586c9a",
   "metadata": {},
   "source": [
    "The method that calculates difference between user profile and the places profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d995af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(vector, place_vector):\n",
    "    return np.square(vector - place_vector).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e77748",
   "metadata": {},
   "source": [
    "The method sorts places by the best fitting ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6521b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_places(vector, places, difference_metric=mse):\n",
    "    buffer = []\n",
    "    for place in places:\n",
    "        buffer.append((place, difference_metric(vector, place[7])))\n",
    "        \n",
    "    buffer.sort(key=lambda x: x[1])\n",
    "    return [b[0] for b in buffer], [b[1] for b in buffer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60d9ae",
   "metadata": {},
   "source": [
    "### Predict the result on given input text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b944854",
   "metadata": {},
   "source": [
    "Set the text for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e06a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I really like eating in bars like that. I would like to drink more beer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3343a",
   "metadata": {},
   "source": [
    "Load model & tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "333b5fac",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/tokenizer_model_1_1680697854.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, tokenizer, dictionary \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m, in \u001b[0;36mload\u001b[0;34m(model_path, tokenizer_path, dictionary_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(model_path, tokenizer_path, dictionary_path):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      3\u001b[0m         tokenizer \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dictionary_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/tokenizer_model_1_1680697854.pickle'"
     ]
    }
   ],
   "source": [
    "model, tokenizer, dictionary = load(model_path, tokenizer_path, dictionary_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956c1d8",
   "metadata": {},
   "source": [
    "Calculate the result vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7279d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = calculate_vector(model, tokenizer, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e686e22",
   "metadata": {},
   "source": [
    "Load places data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data_krakow_vectorized_1680882410', 'rb') as file:\n",
    "    places = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0eb0e5",
   "metadata": {},
   "source": [
    "Sort those places by user interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a4050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "places_sorted, distances = fit_places(result, places)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d240a1",
   "metadata": {},
   "source": [
    "### Visualize the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5ddaa",
   "metadata": {},
   "source": [
    "The method decodes the result vector to human readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6cf5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_vector(vector, dictionary, text):\n",
    "    label_weight = [(dictionary[index], weight) for index, weight in enumerate(vector)]\n",
    "    label_weight.sort(key=lambda x: x[1], reverse=True)\n",
    "    y, x = zip(*label_weight)\n",
    "    x = np.array(x)\n",
    "    x *= 100\n",
    "    \n",
    "    plt.figure(figsize=(10, 0.25*len(y)))\n",
    "    plt.ylabel('Category')\n",
    "    plt.xlabel('Weight in %')\n",
    "    plt.title(f'Result for text \"{text}\"')\n",
    "\n",
    "    plt.plot(x, y, 'r.', label='Category weight')\n",
    "    plt.plot(x, y, 'b', label='Category weight (line)', linewidth=0.5)\n",
    "    plt.xticks(np.arange(0, 101, 10))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f32bd9",
   "metadata": {},
   "source": [
    "The method presents the sorting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73520265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_places(places_sorted, distances, dictionary, text):\n",
    "    y = [f'{place[0]} [{dictionary[np.argmax(place[7])]}]' for place in places_sorted]\n",
    "    x = np.array(distances, dtype='float64')*100\n",
    "    \n",
    "    plt.figure(figsize=(10, 0.25*len(y)))\n",
    "    plt.ylabel('Place name with best fitting category')\n",
    "    plt.xlabel('Difference in %')\n",
    "    plt.title(f'Best fitting places for text \"{text}\"')\n",
    "\n",
    "    plt.plot(x, y, 'r.', label='Difference')\n",
    "    plt.plot(x, y, 'b', label='Difference (line)', linewidth=0.5)\n",
    "    plt.xticks(np.arange(0, 101, 10))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3081d214",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m visualize_vector(\u001b[43mresult\u001b[49m, dictionary, text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_vector(result, dictionary, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_places(places_sorted, distances, dictionary, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d026e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n"
     ]
    }
   ],
   "source": [
    "print('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26931e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
